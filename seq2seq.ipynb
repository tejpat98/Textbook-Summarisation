{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7QXSBvhWN1gdByfThJRkM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejpat98/Textbook-Summarisation/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b4En3CxHwJN"
      },
      "source": [
        "(W.I.P) Implementation of sequence to sequence model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXUYzhe9HuRM"
      },
      "source": [
        "!pip install tensorflow-gpu\r\n",
        "!pip install tensorflow-addons\r\n",
        "!pip install tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J10h4kclIhB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HguLnusJ0m5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2413f6-9e54-4bbf-a468-d011fdda1784"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tfa\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import pandas as pd\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWyTx10JCCY"
      },
      "source": [
        "Prepairing arXiv dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU9_fjjeSn9t"
      },
      "source": [
        "sp_data = pd.read_json('/content/123.json')\r\n",
        "print(sp_data.info())\r\n",
        "print('----------------------------------------------------------------')\r\n",
        "\r\n",
        "sp_cleaned_data = []\r\n",
        "\r\n",
        "# Where 'i' is the article body and 'j' is a sentence\r\n",
        "for i in sp_data['article_text']:\r\n",
        "    for j in i:\r\n",
        "        if j.find(\"@xmath\") != -1 or j.find(\"@xcite\") != -1:\r\n",
        "            # Found a sentence that contains either maths or a citation. --? skip it\r\n",
        "            break\r\n",
        "        # No maths or citations found --> copy paper to sp_cleaned_data\r\n",
        "        sp_cleaned_data = sp_data[i]\r\n",
        "\r\n",
        "sp_cleaned_data.to_json('/content/sp_cleaned.json')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}